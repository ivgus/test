{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivgus/test/blob/main/homeworks/hw01_classification_and_attention/02_hw_fmnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "# Домашнее задание №1\n",
        "## Часть2: Классификация FashionMNIST\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/rads_ai\n",
        "\n",
        "В данном задании вам предстоит решить достаточно простую задачу классификации изображений с помощью сверточных нейронных сетей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6orRHw9RERUo"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbN47tiWERUp"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o3RfZrhzERUq",
        "outputId": "4e18318d-f7fc-40c0-c2e9-bc14d650bb4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-13 10:11:18--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-09-13 10:11:18--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-09-13 10:11:19 (68.5 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H2s51ZlbERUr"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0N_1YXdcERUs"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "aYcL28OsgSq8",
        "outputId": "cbbc1a1b-968c-4701-bb94-e95fa04d5c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 303kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.61MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 18.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 8')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = None\n",
        "# your code here\n",
        "model_task_1 = nn.Sequential(\n",
        "    nn.Conv2d(1,28,5,1,2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(28),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(5488,10),\n",
        "    nn.Softmax()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "d4cb3685-b3c5-4996-e5c1-3b18352df387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 28, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (1): ReLU()\n",
              "  (2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): Dropout(p=0.25, inplace=False)\n",
              "  (5): Flatten(start_dim=1, end_dim=-1)\n",
              "  (6): Linear(in_features=5488, out_features=10, bias=True)\n",
              "  (7): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "d4b44e91-8a2d-4d2b-f6e3-bb27cdc0edac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1773: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "4a0e2583-fe91-4dd5-b8ce-0ce13aceb95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1773: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] err: 1.707\n",
            "[1,   200] err: 1.672\n",
            "[1,   300] err: 1.636\n",
            "[1,   400] err: 1.629\n",
            "[1,   500] err: 1.618\n",
            "[1,   600] err: 1.616\n",
            "[1,   700] err: 1.620\n",
            "[1,   800] err: 1.617\n",
            "[1,   900] err: 1.620\n",
            "[1,  1000] err: 1.603\n",
            "[1,  1100] err: 1.604\n",
            "[1,  1200] err: 1.621\n",
            "[1,  1300] err: 1.617\n",
            "[1,  1400] err: 1.601\n",
            "[1,  1500] err: 1.613\n",
            "[1,  1600] err: 1.591\n",
            "[1,  1700] err: 1.596\n",
            "[1,  1800] err: 1.601\n",
            "Accuracy of the network on the test set: 85 %\n",
            "[2,   100] err: 1.599\n",
            "[2,   200] err: 1.615\n",
            "[2,   300] err: 1.593\n",
            "[2,   400] err: 1.599\n",
            "[2,   500] err: 1.600\n",
            "[2,   600] err: 1.595\n",
            "[2,   700] err: 1.592\n",
            "[2,   800] err: 1.595\n",
            "[2,   900] err: 1.596\n",
            "[2,  1000] err: 1.600\n",
            "[2,  1100] err: 1.584\n",
            "[2,  1200] err: 1.602\n",
            "[2,  1300] err: 1.599\n",
            "[2,  1400] err: 1.589\n",
            "[2,  1500] err: 1.585\n",
            "[2,  1600] err: 1.592\n",
            "[2,  1700] err: 1.593\n",
            "[2,  1800] err: 1.595\n",
            "Accuracy of the network on the test set: 85 %\n",
            "[3,   100] err: 1.584\n",
            "[3,   200] err: 1.584\n",
            "[3,   300] err: 1.581\n",
            "[3,   400] err: 1.580\n",
            "[3,   500] err: 1.584\n",
            "[3,   600] err: 1.585\n",
            "[3,   700] err: 1.581\n",
            "[3,   800] err: 1.583\n",
            "[3,   900] err: 1.575\n",
            "[3,  1000] err: 1.576\n",
            "[3,  1100] err: 1.584\n",
            "[3,  1200] err: 1.582\n",
            "[3,  1300] err: 1.572\n",
            "[3,  1400] err: 1.591\n",
            "[3,  1500] err: 1.578\n",
            "[3,  1600] err: 1.589\n",
            "[3,  1700] err: 1.600\n",
            "[3,  1800] err: 1.580\n",
            "Accuracy of the network on the test set: 86 %\n",
            "[4,   100] err: 1.575\n",
            "[4,   200] err: 1.569\n",
            "[4,   300] err: 1.579\n",
            "[4,   400] err: 1.575\n",
            "[4,   500] err: 1.578\n",
            "[4,   600] err: 1.575\n",
            "[4,   700] err: 1.570\n",
            "[4,   800] err: 1.580\n",
            "[4,   900] err: 1.588\n",
            "[4,  1000] err: 1.590\n",
            "[4,  1100] err: 1.574\n",
            "[4,  1200] err: 1.587\n",
            "[4,  1300] err: 1.588\n",
            "[4,  1400] err: 1.573\n",
            "[4,  1500] err: 1.575\n",
            "[4,  1600] err: 1.585\n",
            "[4,  1700] err: 1.576\n",
            "[4,  1800] err: 1.581\n",
            "Accuracy of the network on the test set: 87 %\n",
            "[5,   100] err: 1.577\n",
            "[5,   200] err: 1.573\n",
            "[5,   300] err: 1.566\n",
            "[5,   400] err: 1.568\n",
            "[5,   500] err: 1.566\n",
            "[5,   600] err: 1.569\n",
            "[5,   700] err: 1.578\n",
            "[5,   800] err: 1.576\n",
            "[5,   900] err: 1.583\n",
            "[5,  1000] err: 1.570\n",
            "[5,  1100] err: 1.584\n",
            "[5,  1200] err: 1.569\n",
            "[5,  1300] err: 1.570\n",
            "[5,  1400] err: 1.583\n",
            "[5,  1500] err: 1.568\n",
            "[5,  1600] err: 1.582\n",
            "[5,  1700] err: 1.575\n",
            "[5,  1800] err: 1.577\n",
            "Accuracy of the network on the test set: 87 %\n",
            "[6,   100] err: 1.582\n",
            "[6,   200] err: 1.562\n",
            "[6,   300] err: 1.569\n",
            "[6,   400] err: 1.570\n",
            "[6,   500] err: 1.578\n",
            "[6,   600] err: 1.573\n",
            "[6,   700] err: 1.566\n",
            "[6,   800] err: 1.571\n",
            "[6,   900] err: 1.567\n",
            "[6,  1000] err: 1.570\n",
            "[6,  1100] err: 1.571\n",
            "[6,  1200] err: 1.567\n",
            "[6,  1300] err: 1.571\n",
            "[6,  1400] err: 1.569\n",
            "[6,  1500] err: 1.570\n",
            "[6,  1600] err: 1.567\n",
            "[6,  1700] err: 1.568\n",
            "[6,  1800] err: 1.571\n",
            "Accuracy of the network on the test set: 87 %\n",
            "[7,   100] err: 1.577\n",
            "[7,   200] err: 1.565\n",
            "[7,   300] err: 1.566\n",
            "[7,   400] err: 1.574\n",
            "[7,   500] err: 1.570\n",
            "[7,   600] err: 1.573\n",
            "[7,   700] err: 1.570\n",
            "[7,   800] err: 1.569\n",
            "[7,   900] err: 1.582\n",
            "[7,  1000] err: 1.569\n",
            "[7,  1100] err: 1.558\n",
            "[7,  1200] err: 1.567\n",
            "[7,  1300] err: 1.564\n",
            "[7,  1400] err: 1.557\n",
            "[7,  1500] err: 1.567\n",
            "[7,  1600] err: 1.566\n",
            "[7,  1700] err: 1.573\n",
            "[7,  1800] err: 1.567\n",
            "Accuracy of the network on the test set: 86 %\n",
            "[8,   100] err: 1.566\n",
            "[8,   200] err: 1.566\n",
            "[8,   300] err: 1.566\n",
            "[8,   400] err: 1.572\n",
            "[8,   500] err: 1.570\n",
            "[8,   600] err: 1.568\n",
            "[8,   700] err: 1.570\n",
            "[8,   800] err: 1.564\n",
            "[8,   900] err: 1.564\n",
            "[8,  1000] err: 1.569\n",
            "[8,  1100] err: 1.571\n",
            "[8,  1200] err: 1.569\n",
            "[8,  1300] err: 1.567\n",
            "[8,  1400] err: 1.568\n",
            "[8,  1500] err: 1.564\n",
            "[8,  1600] err: 1.560\n",
            "[8,  1700] err: 1.573\n",
            "[8,  1800] err: 1.575\n",
            "Accuracy of the network on the test set: 88 %\n",
            "[9,   100] err: 1.572\n",
            "[9,   200] err: 1.565\n",
            "[9,   300] err: 1.562\n",
            "[9,   400] err: 1.573\n",
            "[9,   500] err: 1.557\n",
            "[9,   600] err: 1.556\n",
            "[9,   700] err: 1.560\n",
            "[9,   800] err: 1.555\n",
            "[9,   900] err: 1.574\n",
            "[9,  1000] err: 1.562\n",
            "[9,  1100] err: 1.571\n",
            "[9,  1200] err: 1.568\n",
            "[9,  1300] err: 1.568\n",
            "[9,  1400] err: 1.564\n",
            "[9,  1500] err: 1.564\n",
            "[9,  1600] err: 1.576\n",
            "[9,  1700] err: 1.561\n",
            "[9,  1800] err: 1.560\n",
            "Accuracy of the network on the test set: 87 %\n",
            "[10,   100] err: 1.555\n",
            "[10,   200] err: 1.571\n",
            "[10,   300] err: 1.561\n",
            "[10,   400] err: 1.556\n",
            "[10,   500] err: 1.555\n",
            "[10,   600] err: 1.569\n",
            "[10,   700] err: 1.559\n",
            "[10,   800] err: 1.563\n",
            "[10,   900] err: 1.565\n",
            "[10,  1000] err: 1.561\n",
            "[10,  1100] err: 1.566\n",
            "[10,  1200] err: 1.560\n",
            "[10,  1300] err: 1.552\n",
            "[10,  1400] err: 1.558\n",
            "[10,  1500] err: 1.572\n",
            "[10,  1600] err: 1.570\n",
            "[10,  1700] err: 1.563\n",
            "[10,  1800] err: 1.568\n",
            "Accuracy of the network on the test set: 88 %\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_err = 0.0\n",
        "    for i, data in enumerate(train_data_loader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs.to(device)\n",
        "        outputs = model_task_1(inputs)\n",
        "        err = loss(outputs, labels)\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_err += err.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] err: %.3f' % (epoch + 1, i + 1, running_err / 100))\n",
        "            running_err = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_data_loader:\n",
        "            inputs, labels = data\n",
        "            outputs = model_task_1(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the test set: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "4c3caee0-5cbb-4b2a-e4af-d8eb5f96b9db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1773: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.90577\n"
          ]
        }
      ],
      "source": [
        "model_task_1.to(device)\n",
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "bc4ffa76-4bca-4fe4-bba6-ed204a7cf01b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8868\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J2EZp6_ERUy"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mvwORBfiERUy",
        "outputId": "9a5e0547-79e9-43c7-948b-8e7914c311ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axn7pbrGERUy"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}